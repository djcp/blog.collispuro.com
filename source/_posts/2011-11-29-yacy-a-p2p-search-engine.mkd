--- 
categories: []
comments: true
layout: post
published: true
status: publish
tags: 
  - code
  - freedom
  - java
  - jquery
  - solr
title: "YaCy - a p2p search engine"
type: post
---
So I'm running a <a href="http://collispuro.dyndns.org:8090/">YaCy node</a> - which is a pretty<a href="http://yacy.net/en/"> awesome project to create a search engine indexed "by the people, for the people."</a>

YaCy provides a java servent  that can index internal resources and external web pages. You have MANY controls over what and how it's indexing and the resources allocated to it. There are tons of built-in analytics and logging for the stats geek in you.

It's still rough, but seems damned promising.  A bonus - it uses <a href="http://jquery.org">jQuery</a> and <a href="http://lucene.apache.org">Solr</a>.

I really like the idea of indexing all the content you care about and also providing that index to the world at large to search, but I have concerns over the long-term impact of more 'bots crawling the web. I would like to see YaCy figure out a way to minimize it's impact on a global level - if every yacy node is indexing the same sites, it could easily escalate to a DDoS-level problem. Perhaps they're already working on this issue.
